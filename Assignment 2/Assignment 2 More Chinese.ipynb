{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data, padding (based on 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# device = torch.device('cuda:3')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chinese_data(inputfilename):\n",
    "    with open(inputfilename, \"r\") as inputfile:\n",
    "        sentences = []\n",
    "        collection_words = ['ç']\n",
    "        collection_labels = []\n",
    "        for line in inputfile:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            columns = line.split()\n",
    "            #print(words)\n",
    "            if columns == []:\n",
    "                sentences.append((''.join(collection_words) + 'ñ', collection_labels))\n",
    "                collection_words = []\n",
    "                collection_labels = []\n",
    "                continue\n",
    "            collection_words.append(columns[1])\n",
    "            collection_labels += [1] + ([0] * (len(columns[1]) - 1))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comment\n",
    "Adding a start token 'ç' and an end token 'ñ'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ç看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究底，最後決定的還是自己。ñ', [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_chars(sentences):\n",
    "    megasentence = ''.join(sentences)\n",
    "    char_list = set()\n",
    "    for c in megasentence:\n",
    "        char_list.add(c)\n",
    "    char_list = [0] + list(char_list)\n",
    "    return char_list, {char_list[x]:x for x in range(len(char_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_index, char_index = index_chars([x[0] for x in train_sentences + test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3649\n"
     ]
    }
   ],
   "source": [
    "all_values = char_index. values()\n",
    "max_value = max(all_values) \n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(sentence, index):\n",
    "    return [index[x] for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lengths(sentences, max_length, padding=0):\n",
    "    return [x + ([padding] * (max_length - len(x))) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x, device=\"cpu\"):\n",
    "    converted = [(convert_sentence(x1[0], char_index), x1[1]) for x1 in x]\n",
    "    X, y = zip(*converted)\n",
    "    lengths = [len(x2) for x2 in X]\n",
    "    padded_X = pad_lengths(X, max(lengths))\n",
    "    Xt = torch.LongTensor(padded_X).to(device)\n",
    "    padded_y = pad_lengths(y, max(lengths), padding=-1)\n",
    "    yt = torch.LongTensor(padded_y).to(device)\n",
    "    lengths_t = torch.LongTensor(lengths).to(device)\n",
    "    return Xt, lengths_t, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tensor, train_lengths_tensor, train_y_tensor = create_dataset(train_sentences, device)\n",
    "test_X_tensor, test_lengths_tensor, test_y_tensor = create_dataset(test_sentences, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing the sequences for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching (based on 1.0, 1.1, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher:\n",
    "    def __init__(self, X, lengths, y, device, batch_size=50, max_iter=None):\n",
    "        self.X = X\n",
    "        self.lengths = lengths # We need the lengths to efficiently use the padding.\n",
    "        self.y = y\n",
    "        self.device = device\n",
    "        self.batch_size=batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.curr_iter = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_iter == self.max_iter:\n",
    "            raise StopIteration\n",
    "        permutation = torch.randperm(self.X.size()[0], device=self.device)\n",
    "        permX = self.X[permutation]\n",
    "        permlengths = self.lengths[permutation]\n",
    "        permy = self.y[permutation]\n",
    "        splitX = torch.split(permX, self.batch_size)\n",
    "        splitlengths = torch.split(permlengths, self.batch_size)\n",
    "        splity = torch.split(permy, self.batch_size)\n",
    "        \n",
    "        self.curr_iter += 1\n",
    "        return zip(splitX, splitlengths, splity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Batcher(train_X_tensor, train_lengths_tensor, train_y_tensor, torch.device('cpu'), max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, 150, batch_first=True)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.lin = nn.Linear(150, 2)\n",
    "        self.softmax = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embs = self.emb(x)\n",
    "        packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output1, _ = self.lstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(output1, batch_first=True)\n",
    "        output2 = self.sig1(unpacked)\n",
    "        output3 = self.lin(output2)\n",
    "        return self.softmax(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, lengths, y, vocab_size, emb_size, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "    if not model:\n",
    "        m = Segmenter(vocab_size, emb_size).to(device)\n",
    "    else:\n",
    "        m = model\n",
    "    loss = nn.NLLLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            optimizer.zero_grad()\n",
    "            o = m(batch[0], batch[1])\n",
    "            l = loss(o.permute(0,2,1), batch[2][:, :max(batch[1])])\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 33.48582077026367.\n",
      "Total loss in epoch 1 is 18.672042846679688.\n",
      "Total loss in epoch 2 is 13.95911693572998.\n",
      "Total loss in epoch 3 is 10.847987174987793.\n",
      "Total loss in epoch 4 is 8.672901153564453.\n",
      "Total loss in epoch 5 is 6.825079441070557.\n",
      "Total loss in epoch 6 is 5.620857238769531.\n",
      "Total loss in epoch 7 is 4.421230792999268.\n",
      "Total loss in epoch 8 is 3.560142755508423.\n",
      "Total loss in epoch 9 is 2.812448263168335.\n",
      "Total loss in epoch 10 is 2.171895980834961.\n",
      "Total loss in epoch 11 is 1.8763411045074463.\n",
      "Total loss in epoch 12 is 1.6573987007141113.\n",
      "Total loss in epoch 13 is 1.336803913116455.\n",
      "Total loss in epoch 14 is 1.3257462978363037.\n",
      "Total loss in epoch 15 is 1.6597785949707031.\n",
      "Total loss in epoch 16 is 1.9198561906814575.\n",
      "Total loss in epoch 17 is 2.2084600925445557.\n",
      "Total loss in epoch 18 is 2.0858240127563477.\n",
      "Total loss in epoch 19 is 1.4297027587890625.\n",
      "Total loss in epoch 20 is 1.0907490253448486.\n",
      "Total loss in epoch 21 is 0.9485206604003906.\n",
      "Total loss in epoch 22 is 0.7731131315231323.\n",
      "Total loss in epoch 23 is 0.5622551441192627.\n",
      "Total loss in epoch 24 is 0.36843141913414.\n",
      "Total loss in epoch 25 is 0.26703014969825745.\n",
      "Total loss in epoch 26 is 0.1812802255153656.\n",
      "Total loss in epoch 27 is 0.1328355222940445.\n",
      "Total loss in epoch 28 is 0.10677985101938248.\n",
      "Total loss in epoch 29 is 0.09076306223869324.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1482752/53152826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lengths_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chinese_segmentation.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_s = train(train_X_tensor, train_lengths_tensor, train_y_tensor, len(int_index), 200, 50, 30, \"cpu\")\n",
    "torch.save(model, 'chinese_segmentation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oops guess i didn't save that model properly but anyways i'm doing the evaluation on the same run,\n",
    "#i hope whoever is grading this does not need to run this model again :') sorry sorry'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comment\n",
    "This model and a few more on this notebook had to be trained using cpu instead of cuda because of cuda runtime errors. Since training on cpu is very time-consuming, the models were only trained on 30 epochs (as was done originally) and no further testing with more epochs was done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicter(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_size, 0)\n",
    "        self.lstm = nn.LSTM(self.emb_size, 150, batch_first=True)\n",
    "        self.lin = nn.Linear(150, self.vocab_size) #changed this here, used to be 2 instead of vocab_size\n",
    "        self.softmax = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embs = self.emb(x)\n",
    "        packed = pack_padded_sequence(embs, lengths.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "        output1, _ = self.lstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(output1, batch_first=True)\n",
    "        output3 = self.lin(unpacked)\n",
    "        return self.softmax(output3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, lengths, y, vocab_size, emb_size, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "#     if not model:\n",
    "#         m = Segmenter(vocab_size, emb_size).to(device)\n",
    "#     else:\n",
    "#         m = model\n",
    "    m = Predicter(vocab_size, emb_size).to(device)\n",
    "    loss = nn.NLLLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            optimizer.zero_grad()\n",
    "            o = m(batch[0], batch[1])\n",
    "            l = loss(o[:, :-1, :].permute(0,2,1), batch[0][:, 1:max(batch[1])]) #rip 1st char\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 573.6555786132812.\n",
      "Total loss in epoch 1 is 510.2818603515625.\n",
      "Total loss in epoch 2 is 461.9465637207031.\n",
      "Total loss in epoch 3 is 418.2381286621094.\n",
      "Total loss in epoch 4 is 376.1671142578125.\n",
      "Total loss in epoch 5 is 335.3100891113281.\n",
      "Total loss in epoch 6 is 296.4182434082031.\n",
      "Total loss in epoch 7 is 258.9539489746094.\n",
      "Total loss in epoch 8 is 222.69390869140625.\n",
      "Total loss in epoch 9 is 191.03509521484375.\n",
      "Total loss in epoch 10 is 164.3633575439453.\n",
      "Total loss in epoch 11 is 143.44784545898438.\n",
      "Total loss in epoch 12 is 129.9801788330078.\n",
      "Total loss in epoch 13 is 116.51019287109375.\n",
      "Total loss in epoch 14 is 108.3027114868164.\n",
      "Total loss in epoch 15 is 100.05379486083984.\n",
      "Total loss in epoch 16 is 95.44648742675781.\n",
      "Total loss in epoch 17 is 89.84992980957031.\n",
      "Total loss in epoch 18 is 85.84286499023438.\n",
      "Total loss in epoch 19 is 82.64210510253906.\n",
      "Total loss in epoch 20 is 81.01806640625.\n",
      "Total loss in epoch 21 is 78.18431854248047.\n",
      "Total loss in epoch 22 is 74.24844360351562.\n",
      "Total loss in epoch 23 is 72.7142105102539.\n",
      "Total loss in epoch 24 is 71.36329650878906.\n",
      "Total loss in epoch 25 is 70.84545135498047.\n",
      "Total loss in epoch 26 is 67.39743041992188.\n",
      "Total loss in epoch 27 is 65.11573028564453.\n",
      "Total loss in epoch 28 is 65.0032730102539.\n",
      "Total loss in epoch 29 is 64.54490661621094.\n"
     ]
    }
   ],
   "source": [
    "model = train(train_X_tensor, train_lengths_tensor, train_y_tensor, len(int_index), 200, 50, 30, \"cuda:3\")\n",
    "torch.save(model, 'chinese_generation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments\n",
    "\n",
    "In order to fit the requirements of the task, the size of the linear layer was changed from 2 (in the original model, we were classifying with either 0 or 1) to the length of the vocabulary, as we are now predicting words.\n",
    "\n",
    "The Sigmoid function was removed, since this function is useful for binary classification but not for the task of text generation.\n",
    "\n",
    "In the model's training loop, in order to get the right predictions and loss, the end token of the sentences were removed in the second dimension, as well as the start token in the targets of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation (part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"chinese_generation.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "#average\n",
    "length = 0\n",
    "for sentence in test_sentences:\n",
    "    length += len(sentence[0])\n",
    "\n",
    "avg = length / len(test_sentences)\n",
    "print(int(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_generator():\n",
    "    start_symbol = char_index['ç']\n",
    "    starter = char_index[random.choice(int_index)]\n",
    "    end_symbol = char_index['ñ']\n",
    "    #     variance = 0.25\n",
    "    generated = ''\n",
    "\n",
    "    x = np.zeros((1, 39), dtype=int)\n",
    "    for column in x:\n",
    "        column[0] += start_symbol\n",
    "        column[1] += starter\n",
    "    p = torch.tensor([39])\n",
    "    o = torch.tensor(x).to(device)\n",
    "\n",
    "    for i in range(37):\n",
    "        out = model(o, p)\n",
    "        the_character = torch.argmax(out, 2)\n",
    "        o[0][i+2] += the_character[0][i+2]\n",
    "\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_to_text(t):\n",
    "\n",
    "    sentence = ''\n",
    "    for v in t[0]:\n",
    "        c = int_index[v]\n",
    "        sentence += c\n",
    "    print(sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "壹韌念補。縣南的子中。，留的木更通、敏、害。及生於i》飾於西。）建了子的體。\n"
     ]
    }
   ],
   "source": [
    "b = probabilities_generator()\n",
    "c = probabilities_to_text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梧者業養用宜的子。以，顯為子中的嶼學移。才行，自語由子的篇。及稱王，跡成人的\n"
     ]
    }
   ],
   "source": [
    "b = probabilities_generator()\n",
    "c = probabilities_to_text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佈和，勵的髮照放或能出，送的子與萄的性。及在大中江的殿。，任安的子。，留拒堂\n"
     ]
    }
   ],
   "source": [
    "b = probabilities_generator()\n",
    "c = probabilities_to_text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "禕是大中的面。及彈的池。及王創。，於.發中的型範在子為能，態圈，度的度，掉的\n"
     ]
    }
   ],
   "source": [
    "b = probabilities_generator()\n",
    "c = probabilities_to_text(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments\n",
    "\n",
    "To generate sentences, we use the average sentence length (39).\n",
    "\n",
    "The probabilities_generator function predicts the following character based on the starter symbol plus another character chosen at random from the list of words. When a new character is predicted, it is added to the tensor and used to predict the following word, until the end.\n",
    "\n",
    "(Copy and paste the generated sentences to google translate if you wanna have a laugh, they're quite weird and funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleBoii(nn.Module):\n",
    "    def __init__(self, segmenter, predicter):\n",
    "        super(DoubleBoii, self).__init__()\n",
    "        \n",
    "        self.seg = segmenter\n",
    "        self.pre = predicter\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        \n",
    "        segmentation = self.seg(x, lengths)\n",
    "        prediction = self.pre(x, lengths)\n",
    "        \n",
    "        return segmentation, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, lengths, y, vocab_size, emb_size, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "\n",
    "    seg = Segmenter(vocab_size, emb_size).to(device)\n",
    "    pre = Predicter(vocab_size, emb_size).to(device)\n",
    "    doubleboii = DoubleBoii(seg, pre)\n",
    "\n",
    "    loss = nn.NLLLoss(ignore_index=-1)\n",
    "    optimizer = optim.Adam(doubleboii.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    \n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            optimizer.zero_grad()\n",
    "            o, u = doubleboii(batch[0], batch[1])\n",
    "            l_segmenter = loss(o.permute(0,2,1), batch[2][:, :max(batch[1])]) #loss of segmenter\n",
    "            l_predicter = loss(u[:, :-1, :].permute(0,2,1), batch[0][:, 1:max(batch[1])]) #loss of predicter\n",
    "            tot = l_segmenter + l_predicter\n",
    "            tot_loss += tot\n",
    "            #add two losses before this\n",
    "            tot.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "    return doubleboii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 603.0822143554688.\n",
      "Total loss in epoch 1 is 524.9391479492188.\n",
      "Total loss in epoch 2 is 472.2152404785156.\n",
      "Total loss in epoch 3 is 424.95611572265625.\n",
      "Total loss in epoch 4 is 381.0309143066406.\n",
      "Total loss in epoch 5 is 338.6737060546875.\n",
      "Total loss in epoch 6 is 298.1492614746094.\n",
      "Total loss in epoch 7 is 259.1299743652344.\n",
      "Total loss in epoch 8 is 223.43145751953125.\n",
      "Total loss in epoch 9 is 192.60321044921875.\n",
      "Total loss in epoch 10 is 166.27276611328125.\n",
      "Total loss in epoch 11 is 145.16412353515625.\n",
      "Total loss in epoch 12 is 129.30235290527344.\n",
      "Total loss in epoch 13 is 116.69541931152344.\n",
      "Total loss in epoch 14 is 108.91262817382812.\n",
      "Total loss in epoch 15 is 100.5002212524414.\n",
      "Total loss in epoch 16 is 94.72045135498047.\n",
      "Total loss in epoch 17 is 89.19795989990234.\n",
      "Total loss in epoch 18 is 88.46723175048828.\n",
      "Total loss in epoch 19 is 84.53884887695312.\n",
      "Total loss in epoch 20 is 82.37654113769531.\n",
      "Total loss in epoch 21 is 78.7981948852539.\n",
      "Total loss in epoch 22 is 77.51995849609375.\n",
      "Total loss in epoch 23 is 72.31248474121094.\n",
      "Total loss in epoch 24 is 71.4969482421875.\n",
      "Total loss in epoch 25 is 69.60501861572266.\n",
      "Total loss in epoch 26 is 67.2027587890625.\n",
      "Total loss in epoch 27 is 65.66841125488281.\n",
      "Total loss in epoch 28 is 63.78589630126953.\n",
      "Total loss in epoch 29 is 62.936988830566406.\n"
     ]
    }
   ],
   "source": [
    "momo = train(train_X_tensor, train_lengths_tensor, train_y_tensor, len(int_index), 200, 50, 30, device)\n",
    "torch.save(momo, 'chinese_doubleboii.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments\n",
    "\n",
    "To make this model, the two previous models are combined via a class (DoubleBoii), which returns the output tensors for both models.\n",
    "\n",
    "In the training loop, one loss is calculated for each of the two models, and then concatenated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (emb): Embedding(3650, 200, padding_idx=0)\n",
       "  (lstm): LSTM(200, 150, batch_first=True)\n",
       "  (sig1): Sigmoid()\n",
       "  (lin): Linear(in_features=150, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rawpredictions_s = model_s(test_X_tensor, test_lengths_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_s = torch.argmax(rawpredictions_s, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectpreds_s = []\n",
    "collecty_s = []\n",
    "for i in range(test_X_tensor.size(0)):\n",
    "    collectpreds_s.append(predictions_s[i][:test_lengths_tensor[i]])\n",
    "    collecty_s.append(test_y_tensor[i][:test_lengths_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds_s = torch.cat(collectpreds_s)\n",
    "classes_s = torch.cat(collecty_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_s = classes_s.float()\n",
    "allpreds_s = allpreds_s.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10844.), tensor(667.), tensor(6447.), tensor(747.))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_s = sum(classes_s * allpreds_s)\n",
    "fp_s = sum(classes_s * (~allpreds_s.bool()).float())\n",
    "tn_s = sum((~classes_s.bool()).float() * (~allpreds_s.bool()).float())\n",
    "fn_s = sum((~classes_s.bool()).float() * allpreds_s)\n",
    "\n",
    "tp_s, fp_s, tn_s, fn_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9244)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_s = (tp_s + tn_s) / (tp_s + fp_s + tn_s + fn_s)\n",
    "accuracy_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9356)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_s = tp_s / (tp_s + fn_s)\n",
    "recall_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9421)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_s = tp_s / (tp_s + fp_s)\n",
    "precision_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9388)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_s = (2 * recall_s * precision_s) / (recall_s + precision_s)\n",
    "f1_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d = torch.load('chinese_doubleboii.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleBoii(\n",
       "  (seg): Segmenter(\n",
       "    (emb): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (sig1): Sigmoid()\n",
       "    (lin): Linear(in_features=150, out_features=2, bias=True)\n",
       "    (softmax): LogSoftmax(dim=2)\n",
       "  )\n",
       "  (pre): Predicter(\n",
       "    (emb): Embedding(3650, 200, padding_idx=0)\n",
       "    (lstm): LSTM(200, 150, batch_first=True)\n",
       "    (lin): Linear(in_features=150, out_features=3650, bias=True)\n",
       "    (softmax): LogSoftmax(dim=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rawpredictions_d, _ = model_d(test_X_tensor, test_lengths_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_d = torch.argmax(rawpredictions_d, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectpreds_d = []\n",
    "collecty_d = []\n",
    "for i in range(test_X_tensor.size(0)):\n",
    "    collectpreds_d.append(predictions_d[i][:test_lengths_tensor[i]])\n",
    "    collecty_d.append(test_y_tensor[i][:test_lengths_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds_d = torch.cat(collectpreds_d)\n",
    "classes_d = torch.cat(collecty_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_d = classes_d.float()\n",
    "allpreds_d = allpreds_d.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6324.), tensor(5187.), tensor(3327.), tensor(3867.))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_d = sum(classes_d * allpreds_d)\n",
    "fp_d = sum(classes_d * (~allpreds_d.bool()).float())\n",
    "tn_d = sum((~classes_d.bool()).float() * (~allpreds_d.bool()).float())\n",
    "fn_d = sum((~classes_d.bool()).float() * allpreds_d)\n",
    "\n",
    "tp_d, fp_d, tn_d, fn_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5160)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_d = (tp_d + tn_d) / (tp_d + fp_d + tn_d + fn_d)\n",
    "accuracy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6205)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_d = tp_d / (tp_d + fn_d)\n",
    "recall_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5494)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_d = tp_d / (tp_d + fp_d)\n",
    "precision_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5828)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_d = (2 * recall_d * precision_d) / (recall_d + precision_d)\n",
    "f1_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments\n",
    "\n",
    "It is not possible to see exactly at around what epoch the models converge because, due to cuda runtime errors, the models were only trained in 30 epochs. In 30 epochs, it is complicated to point where the models converge.\n",
    "\n",
    "Regardless, the accuracy scores of the models are 0.9244 for the segmentation model and 0.5160 for the dual model. The segmentation model is, then, more accurate than the dual model. Their F1 scores are 0.9388 for the segmentation model and 0.5828 for the dual model. Again, the segmentation model has a higher score, which denotes better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity of predicter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_p(X, lengths, y, vocab_size, emb_size, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(X, lengths, y, device, batch_size=batch_size, max_iter=epochs)\n",
    "\n",
    "    m = Predicter(vocab_size, emb_size).to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        for batch in split:\n",
    "            o = m(batch[0], batch[1])\n",
    "            l = loss(o[:, :-1, :].permute(0,2,1), batch[0][:, 1:max(batch[1])]) \n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "    p = torch.exp(tot_loss)\n",
    "    print(\"Perplexity is {}.\".format(p))\n",
    "\n",
    "    return p.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = torch.load('chinese_generation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity is 3.509243098723996e+35.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.509243098723996e+35"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_p(test_X_tensor, test_lengths_tensor, test_y_tensor, len(int_index), 200, 50, 30, device, model_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity of dual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity is 3.897350175616371e+35.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.897350175616371e+35"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_p(test_X_tensor, test_lengths_tensor, test_y_tensor, len(int_index), 200, 50, 30, device, model_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comments\n",
    "\n",
    "The result of the perplexity is high in both models, which is bad. The perplexity of the predicter model is a little bit lower than the perplexity of the dual model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
